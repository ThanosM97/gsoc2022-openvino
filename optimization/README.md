<h1 align="center">Model optimization with OpenVINO Toolkit using synthetic datasets</h1>

The [OpenVINO](https://docs.openvino.ai/latest/index.html) (Open Visual Inference and Neural network Optimization) Toolkit is an open-source tool, originally developed by Intel, that enables optimization of deep learning models and deployment on Intel hardware using a developed inference engine.

## Model Optimizer

The purpose of OpenVINO's model optimizer is to convert deep learning models developed on several frameworks (e.g. TensorFlow, PyTorch, Caffe, etc.) to an Intermediate Representation (IR) of the model which enables inference on OpenVINO's runtime. The produced IR model is optimized for the selected target device, improving the inference speed and at the same time keeping the model's accuracy constant. The IR model can be further optimized using the OpenVINO's Post-training Optimization Tool. For more information about the model optimizer, refer to the [official documentation](https://docs.openvino.ai/latest/openvino_docs_MO_DG_Deep_Learning_Model_Optimizer_DevGuide.html).

<p align="center">
<img src="https://user-images.githubusercontent.com/41332813/188279350-a7a6af05-53c3-4ba4-a8a9-26707633b43e.png" alt="Model Optimizer Workflow" width="600"/>
</p>
<p align="center"> Model Optimizer Workflow (<a href="https://docs.openvino.ai/latest/openvino_docs_MO_DG_Deep_Learning_Model_Optimizer_DevGuide.html">source</a>)</p>


## Post-training Optimization Tool

OpenVINO's Post-training Optimization Tool provides two quantization methods to optimize a model's performance. Since it is performed post-training, it does not require a dataset, but rather a representative calibration set (e.g., 300 samples). Furthermore, the model has to be first converted to OpenVINO's IR format. Granted these requirements, a floating-precision model (FP32 or FP16) can be quantized to 8-bit integer-precision using either the [Default Quantization](https://docs.openvino.ai/latest/pot_default_quantization_usage.html#doxid-pot-default-quantization-usage) algorithm, or the [Accuracy-aware](https://docs.openvino.ai/latest/pot_accuracyaware_usage.html#doxid-pot-accuracyaware-usage) quantization algorithm. The former is recommended as a first step, since it leads to satisfactory  performance for the majority of the cases and it only requires an unannotated calibration dataset, while the latter focuses on keeping the accuracy at a specific range, thus requiring an annotated calibration dataset. Figure 2 showcases the optimization workflow.

<p align="center">
<img src="https://user-images.githubusercontent.com/41332813/188279380-886d8193-3ea6-456a-9848-dde107d8f228.png" alt="Post-training Model Optimization Workflow" width="600"/>
</p>
<p align="center"> Post-training Model Optimization Workflow (<a href="https://docs.openvino.ai/latest/pot_introduction.html#doxid-pot-introduction">source</a>)</p>

## Experiments
The DiStyleGAN model, developed at the first part of this project, generates images from the distribution of the CIFAR-10 dataset. Therefore, we experimented with PyTorch models, pre-trained on CIFAR-10 for classification. In our experiments, we used both the Default Quantization and the Accuracy-control quantization methods provided by the OpenVINO Post-training Optimization Tool.  The same experiments were conducted using multiple calibration datasets, and we compared the results of the quantized models for the classification task on the official CIFAR-10 test set.

### PyTorch Models
We opted to quantize PyTorch models, pre-trained on CIFAR-10 for classification. These models were obtained from the [chenyaofo/pytorch-cifar-models](https://github.com/chenyaofo/pytorch-cifar-models) repository on GitHub. In particular, we used the following models:

* ResNet20 (resnet20)
* VGG16 (vgg16_bn)
* MobileNetV2 (mobilenetv2_x1_4)
* ShuffleNetV2 (shufflenetv2_x2_0)
* RepVGG (repvgg_a2)

### Calibration Datasets
For the quantization process, the OpenVINO POT requires a calibration dataset. The goal of the project is to use synthetic images generated by DiStyleGAN as the calibration dataset. However, we also conducted the quantization using three other datasets. In particular, we use the following calibration datasets in our experiments:

* Official [CIFAR-10](https://www.cs.toronto.edu/~kriz/cifar.html) training set
* Synthetic images generated by [StyleGAN2-ADA](https://github.com/NVlabs/stylegan2-ada-pytorch)
* Synthetic images generated by [DiStyleGAN](https://github.com/ThanosM97/gsoc2022-openvino)
* Fractal images generated by using the [Datumaro's repository](https://github.com/openvinotoolkit/datumaro) on GitHub
**(It is important to note that while the synthetic datasets above approximate the CIFAR-10 distribution, thus could be considered representative, the fractal images do not constitute a representative dataset for the deep learning models pre-trained on CIFAR-10.)**

We used 5,000 images from each of the aforementioned datasets, 500 images per class of the CIFAR-10 dataset. These subsets can be downloaded from , or you can generate them following the instructions in the links. We then evaluated the results of the quantization methods on the classification task, for the selected PyTorch models, using the CIFAR-10 test set.

## Getting Started
1. Clone the [GitHub repository](https://github.com/ThanosM97/gsoc2022-openvino).
2. Install the python packages in the [requirements](./requirements.txt) file, obtained from the official [openvino_notebooks](https://github.com/openvinotoolkit/openvino_notebooks) repository. (Python 3.8)
3. Download the synthetic calibration datasets from [here](https://drive.google.com/file/d/1e38vn-_VHMcGDkEUvTOUaaX8HuIkDGf9/view?usp=sharing).
4. Run the the notebooks.
