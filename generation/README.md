<h1 align="center"> Development of a lightweight class-conditional GAN for image generation on CIFAR10</h1>

## Dataset

<p align="center">
<img src="https://user-images.githubusercontent.com/41332813/178466035-9ae8db92-cacd-4502-8414-34ccd375f321.png" alt="CIFAR10" width="600"/>
</p>
<p align="center"> The classes of CIFAR-10, along with 10 random images from each. </p>

The CIFAR-10 dataset consists of 60,000 colour images from 10 different class categories, with 6,000 images per class. 
Although the spatial size of each image is small (32x32), it is still complex enough to require a large model to generate 
quality images. In particular, the current state of the art model in Class-conditional Image Generation on CIFAR-10 is StyleGAN2, 
which contains more than 20 million trainable parameters. More information about the dataset can be found on the 
[official website](https://www.cs.toronto.edu/~kriz/cifar.html).


## Knowledge Distillation

In the case of the CIFAR-10 dataset, we opted to distil the StyleGAN2-ADA model. The aforementioned model is able to achieve 
state-of-the-art performance on the task of conditional image generation on the CIFAR-10 dataset. The main reason behind its 
success was the proposed adaptive discriminator augmentation mechanism that significantly stabilizes training when there are limited 
data available. However, in our case the model was utilized for black-box image generation. So despite the training procedure and 
techniques followed by the study, we only needed access to the input-output pairs of the model's generator. In particular we used the official 
[PyTorch implementation of the StyleGAN2-ADA model](https://github.com/NVlabs/stylegan2-ada-pytorch) by NVIDIA Research Projects from Github, 
along with the provided weights for the pre-trained model on the CIFAR-10 dataset, for conditional image generation. Therefore, StyleGAN was used to 
create a [FakeCIFAR10](#fakecifar10) dataset, consisting of images generated by the model, along with the input noise vectors and labels. Subsequently, 
this dataset was used to train the student network to mimic the functionality of the teacher network (*i.e.* StyleGAN2-ADA), using several 
[objectives](https://github.com/ThanosM97/gsoc2022-openvino/wiki/Objectives). On the other hand, the StyleGAN2-ADA model, upon the creation of the dataset, 
was no longer used in the training procedure of the student network, and thus it could be discarded.

## FakeCIFAR10
The FakeCIFAR10 dataset consists of 30,000 synthetic images, generated by the StyleGAN2-ADA model. There are 3,000 images for each of the 10 classes, 
along with the noise vectors that were used as input to StyleGAN's Generator. The dataset was generated using 
the [create_dataset.py](./create_dataset.py) script, and it can be found [here](https://drive.google.com/file/d/1Akx9qLfbA-0cq9vbXC6FerYCADs-YeJj/view?usp=sharing).

```
$ python create_dataset.py -h
usage: create_dataset.py [-h] -p PATH -c CHECKPOINT [-n NSAMPLES] [-b BATCH_SIZE] [-d {cpu,cuda}]

options:
  -h, --help            show this help message and exit
  -p PATH, --path PATH  Path to save the generated images to.
  -c CHECKPOINT, --checkpoint CHECKPOINT
                        Path to StyleGAN2's checkpoint for CIFAR-10.
  -n NSAMPLES, --nsamples NSAMPLES
                        Number of samples per class.
  -b BATCH_SIZE, --batch_size BATCH_SIZE
                        Number of samples per minibatch.
  -d {cpu,cuda}, --device {cpu,cuda}
                        Device to use for the image generation
```                        

In order to run the script, please adhere to the [requirements](https://github.com/NVlabs/stylegan2-ada-pytorch#requirements) of the 
StyleGAN2-ADA model from its official repository. Note that the script can also be executed without a GPU.

## DiStyleGAN

### Getting Started
1. Download the FaceCIFAR10 dataset from [here](https://drive.google.com/file/d/1Akx9qLfbA-0cq9vbXC6FerYCADs-YeJj/view?usp=sharing) and extract the zip file.
2. Install the python packages in the [requirements](../requirements.txt) file. (Python 3.10)
3. Train the model using the example below.

### Training DiStyleGAN
In order to train from scratch DiStyleGAN from Python, you can use the code below:

```python
from distylegan import DiStyleGAN
model = DiStyleGAN()
model.train(
    dataset="./fakecifar/dataset", 
    save="results",
    epochs=200,
    batch_size=128,
    gstep=10,
    checkpoint_interval=20
)
```
